{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy import mean, std\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "train = pd.read_csv('data/train_prep_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test = pd.read_csv('data/test_prep_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32462, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16232, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32462, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(columns=['target'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16232, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.drop(columns=['target'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32462,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train['target']\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16232,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test['target']\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical features\n",
    "num_features = ['age','education','hours_per_week']\n",
    "\n",
    "# numerical transformer\n",
    "num_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "cat_features = ['workclass','marital_status','occupation','relationship',\n",
    "               'race','sex','capital_change','native_country']\n",
    "\n",
    "# categorical transformer\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model pipeline\n",
    "\n",
    "logistic_regression = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',LogisticRegression(random_state=20210510, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 5.266s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time1 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluations can be put in the end\n",
    "# for different models comparison\n",
    "# create functions for repeatations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "def print_score(model):\n",
    "    print('model score: %.3f' % model.score(X_test,y_test))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.843\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross validation accracy score: 0.843 (0.010)\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation\n",
    "\n",
    "# cross validation\n",
    "cv = KFold(n_splits=10, random_state=20210517, shuffle=True)\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(logistic_regression, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('K-fold cross validation accracy score: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification reports\n",
    "\n",
    "def print_classfication_reports(model):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    print('Classification report on test data:')\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    print('Classification report on train data:')\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     12397\n",
      "           1       0.71      0.57      0.63      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     24635\n",
      "           1       0.71      0.58      0.64      7827\n",
      "\n",
      "    accuracy                           0.84     32462\n",
      "   macro avg       0.79      0.75      0.77     32462\n",
      "weighted avg       0.84      0.84      0.84     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification reports\n",
    "print_classfication_reports(logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best params:\n",
      "{'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': [0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, scoring='precision', verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 1.335s\n",
      "model score: 0.844\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     12397\n",
      "           1       0.71      0.57      0.63      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     24635\n",
      "           1       0.71      0.57      0.63      7827\n",
      "\n",
      "    accuracy                           0.84     32462\n",
      "   macro avg       0.79      0.75      0.77     32462\n",
      "weighted avg       0.83      0.84      0.84     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole model pipeline with best params\n",
    "\n",
    "logistic_regression = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',LogisticRegression(C=0.1, random_state=20210510, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time3 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time3)\n",
    "\n",
    "# model evaluation\n",
    "print_score(logistic_regression)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 1.738s\n",
      "model score: 0.842\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     12397\n",
      "           1       0.71      0.57      0.63      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.83      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90     24635\n",
      "           1       0.71      0.57      0.63      7827\n",
      "\n",
      "    accuracy                           0.84     32462\n",
      "   macro avg       0.79      0.75      0.77     32462\n",
      "weighted avg       0.83      0.84      0.83     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model with feature selection\n",
    "\n",
    "logistic_regression = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(LogisticRegression(C=0.1, random_state=20210510), max_features=30)),\n",
    "    ('classifier',LogisticRegression(C=0.1, random_state=20210510, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time3 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time3)\n",
    "\n",
    "# model evaluation\n",
    "print_score(logistic_regression)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Logistic Regression with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing stay the same\n",
    "# only edit the whole model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampler\n",
    "adasyn = ADASYN(random_state=20210517,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# as 'pipeline' in sklearn library does not support 'adasyn'\n",
    "# 'adasyn' function has no .fit_transform\n",
    "# have to use 'make_pipeline' in imblearn library\n",
    "\n",
    "logistic_adasyn = make_pipeline(preprocessor, adasyn ,LogisticRegression(random_state=20210510, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['age', 'education',\n",
       "                                                   'hours_per_week']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['workclass',\n",
       "                                                   'marital_status',\n",
       "                                                   'occupation', 'relationship',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'capital_change',\n",
       "                                                   'native_country'])])),\n",
       "                ('adasyn', ADASYN(n_jobs=-1, random_state=20210517)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(n_jobs=-1, random_state=20210510))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 37.130s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logistic_adasyn.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time2 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.771\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83     12397\n",
      "           1       0.51      0.87      0.64      3835\n",
      "\n",
      "    accuracy                           0.77     16232\n",
      "   macro avg       0.73      0.81      0.74     16232\n",
      "weighted avg       0.85      0.77      0.79     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83     24635\n",
      "           1       0.52      0.88      0.65      7827\n",
      "\n",
      "    accuracy                           0.77     32462\n",
      "   macro avg       0.74      0.81      0.74     32462\n",
      "weighted avg       0.85      0.77      0.79     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(logistic_adasyn)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(logistic_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Linear Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing stay the same\n",
    "# only edit the whole model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model pipeline\n",
    "\n",
    "linear_svc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',LinearSVC(random_state=20210518))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 4.594s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "linear_svc.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time3 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.844\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     12397\n",
      "           1       0.71      0.57      0.63      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     24635\n",
      "           1       0.72      0.57      0.64      7827\n",
      "\n",
      "    accuracy                           0.84     32462\n",
      "   macro avg       0.80      0.75      0.77     32462\n",
      "weighted avg       0.84      0.84      0.84     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(linear_svc)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best params:\n",
      "{'classifier__C': 10, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__loss': ['hinge','squared_hinge'],\n",
    "    'classifier__C': [0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(linear_svc, param_grid, scoring='precision', verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 5.588s\n",
      "model score: 0.844\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     12397\n",
      "           1       0.71      0.58      0.64      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     24635\n",
      "           1       0.71      0.58      0.64      7827\n",
      "\n",
      "    accuracy                           0.84     32462\n",
      "   macro avg       0.79      0.75      0.77     32462\n",
      "weighted avg       0.84      0.84      0.84     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole model pipeline with best params\n",
    "\n",
    "linear_svc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',LinearSVC(C=10, random_state=20210518))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "linear_svc.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time3 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time3)\n",
    "\n",
    "# model evaluation\n",
    "print_score(linear_svc)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 K Nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing stay the same\n",
    "# only edit the whole model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model pipeline\n",
    "\n",
    "kneighbors = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 0.115s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "kneighbors.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time4 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.825\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89     12397\n",
      "           1       0.64      0.58      0.61      3835\n",
      "\n",
      "    accuracy                           0.82     16232\n",
      "   macro avg       0.76      0.74      0.75     16232\n",
      "weighted avg       0.82      0.82      0.82     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     24635\n",
      "           1       0.77      0.69      0.73      7827\n",
      "\n",
      "    accuracy                           0.88     32462\n",
      "   macro avg       0.84      0.81      0.82     32462\n",
      "weighted avg       0.87      0.88      0.87     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(kneighbors)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(kneighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best params:\n",
      "{'classifier__n_neighbors': 50}\n"
     ]
    }
   ],
   "source": [
    "# grid search 1\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [5, 10, 25, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(kneighbors, param_grid, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best params:\n",
      "{'classifier__n_neighbors': 40}\n"
     ]
    }
   ],
   "source": [
    "# grid search 2\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [30, 40, 50, 60, 70, 80, 90]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(kneighbors, param_grid, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 0.159s\n",
      "model score: 0.843\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     12397\n",
      "           1       0.71      0.57      0.63      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     24635\n",
      "           1       0.73      0.60      0.66      7827\n",
      "\n",
      "    accuracy                           0.85     32462\n",
      "   macro avg       0.81      0.77      0.78     32462\n",
      "weighted avg       0.84      0.85      0.85     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole model pipeline with best params\n",
    "\n",
    "kneighbors = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',KNeighborsClassifier(n_neighbors=40))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "kneighbors.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time4 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time4)\n",
    "\n",
    "# model evaluation\n",
    "print_score(kneighbors)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(kneighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing stay the same\n",
    "# only edit the whole model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model pipeline\n",
    "\n",
    "decision_tree = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=20210521, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 2.039s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time5 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.783\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85     12397\n",
      "           1       0.54      0.60      0.57      3835\n",
      "\n",
      "    accuracy                           0.78     16232\n",
      "   macro avg       0.70      0.72      0.71     16232\n",
      "weighted avg       0.79      0.78      0.79     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24635\n",
      "           1       0.86      0.99      0.92      7827\n",
      "\n",
      "    accuracy                           0.96     32462\n",
      "   macro avg       0.93      0.97      0.95     32462\n",
      "weighted avg       0.96      0.96      0.96     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(decision_tree)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n",
      "Best params:\n",
      "{'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# grid search 1\n",
    "\n",
    "depth = [\n",
    "    1, 2, 3, 4, 5,\n",
    "    6, 7, 8, 9, 10,\n",
    "    12, 14, 16, 18, 20\n",
    "]\n",
    "\n",
    "num_leaf = [\n",
    "    1, 2, 3, 4, 5,\n",
    "    6, 7, 8, 9, 10,\n",
    "    12, 14, 16, 18, 20\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "        'classifier__max_depth': depth,\n",
    "        'classifier__min_samples_leaf': num_leaf\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params:\n",
      "{'classifier__max_depth': 60}\n"
     ]
    }
   ],
   "source": [
    "# grid search 2\n",
    "\n",
    "depth = [\n",
    "    20, 30, 40, 50, 60,\n",
    "    70, 80, 90, 100, 200\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "        'classifier__max_depth': depth\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, scoring='precision', verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 1.851s\n",
      "model score: 0.783\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85     12397\n",
      "           1       0.54      0.60      0.57      3835\n",
      "\n",
      "    accuracy                           0.78     16232\n",
      "   macro avg       0.70      0.72      0.71     16232\n",
      "weighted avg       0.79      0.78      0.79     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24635\n",
      "           1       0.86      0.99      0.92      7827\n",
      "\n",
      "    accuracy                           0.96     32462\n",
      "   macro avg       0.93      0.97      0.95     32462\n",
      "weighted avg       0.96      0.96      0.96     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole model pipeline with best params\n",
    "\n",
    "decision_tree = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=60, random_state=20210521, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time5 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time5)\n",
    "\n",
    "# model evaluation\n",
    "print_score(decision_tree)\n",
    "\n",
    "# classification reports\n",
    "\n",
    "print_classfication_reports(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 2.536s\n",
      "model score: 0.775\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.84     12397\n",
      "           1       0.52      0.70      0.60      3835\n",
      "\n",
      "    accuracy                           0.77     16232\n",
      "   macro avg       0.71      0.75      0.72     16232\n",
      "weighted avg       0.81      0.77      0.79     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91     24635\n",
      "           1       0.67      0.93      0.78      7827\n",
      "\n",
      "    accuracy                           0.87     32462\n",
      "   macro avg       0.82      0.89      0.85     32462\n",
      "weighted avg       0.90      0.87      0.88     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model with feature selection\n",
    "\n",
    "decision_tree = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(\n",
    "        DecisionTreeClassifier(max_depth=60, random_state=20210521, class_weight='balanced'), \n",
    "        max_features=60)\n",
    "    ),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=60, random_state=20210521, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time5 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time5)\n",
    "\n",
    "# model evaluation\n",
    "print_score(decision_tree)\n",
    "\n",
    "# classification reports\n",
    "\n",
    "print_classfication_reports(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search try scoring focus on precision\n",
    "# check regression parameters\n",
    "## drop col with low coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
