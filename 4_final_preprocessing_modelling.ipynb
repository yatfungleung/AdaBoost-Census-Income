{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from numpy import mean, std\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data\n",
    "train = pd.read_csv('data/train_prep_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test = pd.read_csv('data/test_prep_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32462, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16232, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32462, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(columns=['target'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16232, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.drop(columns=['target'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32462,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train['target']\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16232,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test['target']\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical features\n",
    "num_features = ['age','education','hours_per_week']\n",
    "\n",
    "# numerical transformer\n",
    "num_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "cat_features = ['workclass','marital_status','occupation','relationship',\n",
    "               'race','sex','capital_change','native_country']\n",
    "\n",
    "# categorical transformer\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model pipeline\n",
    "\n",
    "logistic_regression = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',LogisticRegression(random_state=20210510, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 5.057s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time1 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluations can be put in the end\n",
    "# for different models comparison\n",
    "# create functions for repeatations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "def print_score(model):\n",
    "    print('model score: %.3f' % model.score(X_test,y_test))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.843\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross validation accracy score: 0.843 (0.010)\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation\n",
    "\n",
    "# cross validation\n",
    "cv = KFold(n_splits=10, random_state=20210517, shuffle=True)\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(logistic_regression, X_test, y_test, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('K-fold cross validation accracy score: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification reports\n",
    "\n",
    "def print_classfication_reports(model):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    print('Classification report on test data:')\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    print('Classification report on train data:')\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     12397\n",
      "           1       0.71      0.57      0.63      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     24635\n",
      "           1       0.71      0.58      0.64      7827\n",
      "\n",
      "    accuracy                           0.84     32462\n",
      "   macro avg       0.79      0.75      0.77     32462\n",
      "weighted avg       0.84      0.84      0.84     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification reports\n",
    "print_classfication_reports(logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression: ROC AUD = 0.894\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdxklEQVR4nO3df7hcVX3v8fcnvyAmkFhztDQhJGBAEAHhQJQCBSmaRHvR6w8Qq49KG0Gi5RG9RMnFikjjRb2VouZGjEhLza2CNIVASnsbIyAQIjEEIpgGAkfgIWikBJDkJN/7x96Jk8nMnH1yZs+emf15Pc95zuy91+z5Lk7Y39lr7bWWIgIzMyuvYUUHYGZmxXIiMDMrOScCM7OScyIwMys5JwIzs5IbUXQAgzVhwoSYMmVK0WGYmXWUVatWPRsRPbWOdVwimDJlCvfdd1/RYZiZdRRJG+sdc9OQmVnJORGYmZWcE4GZWck5EZiZlZwTgZlZyeWWCCQtkvSMpLV1jkvSVZLWS1oj6di8YjEzs/ryfHz0WuBq4Lo6x2cC09Kf6cC30t9mZnWt2riZeT96gHVPP9/0cw8TREA7zcksfh+PgI+dcjBzZx3e1M/ILRFExApJUxoUORO4LpJ5sO+WNF7SARHxVF4xmZXNzovmf27aQkSwbcfQzld5Uao2fFhycHtVgWGCEcNE//ZgB2kzhGBHhqvtMGCIIQ9KlphaLapeL1ixAaCpyaDIAWUTgScqtvvSfXskAkmzgdkAkydPbklwZkV759V3sLrvuV3bw4ARw8XW6ittFQGjRw3j5W079rgoD1Wj022vc8XeEewW846BTlT53qyBlcxtDz7dNYlANfbV/OcREQuBhQC9vb1tmLPNalu1cTN/+b2V/ObFbUM+1w4YMAlA8j/Ri1t9Ce1mM17/h009X5GJoA84sGJ7EvBkQbGY7ZX5S9fx3Tsf5eVmf/W2QriPoPWWAHMkLSbpJH7O/QPWjqqbaMpsb/sIRg4T23b2ESg5T5bcOVz1y50ybQLXnevnS5oht0Qg6fvAqcAESX3A54GRABGxAFgKzALWAy8CH8krFrN65i9dt6vzrd1l7SMYBozZZzgv9+/YVXbS+H25Y+7p+QdpHSnPp4beP8DxAC7I6/PNKn3oO/ew4pfPFh3GoO07YhjX/+WbOO6gVxYdinWxjpuG2qyeVRs38+FF9/D8y9uLDmUPo0cMY93lM4sOw6wmJwLreGd8dTm/3PRCoTGMHTWctZfNKDQGs73lRGAdpagmnrye1jBrB04E1tYO+ewtTR8UVcsxk8Zx05yT8v8gszbkRGBtJe+nePzIodmenAisLRx/+e1s2rK1KecaMQzWX/H2ppzLrAycCKwwzezkHTFMXHbmkZwz3XNRmQ2WE4G1VLNG6bqJx6x5nAgsV81q87/h/BM9qMosJ04ElovD593KS/17PwPm+NEjWP35tzUxIjOrx4nAmqYZz/i7yces9ZwIrCkOnnvLXi8i4ou/WbGcCGzIpsy9ZdDv8dw7Zu3DicD22knz/52+3/4uU1lf+M3alxOBDdqRl97Glq3ZZvj0PPhm7c+JwDIbTD/AY/M9stesUzgR2IAGMwJYwKNOAmYdxYnAGhpMR7Cbgcw6kxOB1ZU1CXgKZ7PO5kRge8g6LYSf/zfrDk4EtpssdwHTesZw+0Wn5h+MmbWEE4HtkiUJ+Gkgs+7jRGCZm4KcBMy6kxNByWVZGaxn7ChWzjujRRGZWas5EZTYMV9Yxm9f6m9YxncBZt1vWNEBWDGOv/z2hklgWs8YJwGzkvAdQclkaQryamBm5eJEUCJ+KsjManEiKAE/FWRmjbiPoMs5CZjZQHxH0MWyrCHsBWPMLNdEIGkG8HVgOHBNRMyvOj4O+AdgchrLVyLiu3nGVAYXLr6fm1Y/2bCMp4s2s51ySwSShgPfAM4A+oCVkpZExEMVxS4AHoqIP5PUAzws6fqIaPxYi9WVpUPYTwWZWaU8+whOANZHxIb0wr4YOLOqTAD7SRIwFvgN0HiEk9U0f+k6JwEz2yt5Ng1NBJ6o2O4DqucsvhpYAjwJ7AecFRF7rIYoaTYwG2Dy5Mm5BNvJXvu5W+jPsIakk4CZ1ZLnHYFq7Iuq7bcBq4E/Ao4Brpa0/x5vilgYEb0R0dvT09PsODvalLkDJ4HRI4bx2Py3OwmYWU153hH0AQdWbE8i+eZf6SPA/IgIYL2kR4HXAffmGFfX8AAxM2uGPO8IVgLTJE2VNAo4m6QZqNLjwOkAkl4DHAYM/NC7DZgETpk2wUnAzDLJ7Y4gIvolzQGWkTw+uigiHpR0Xnp8AfBF4FpJD5A0JV0cEY0ffDcOn3drw+NOAGY2GLmOI4iIpcDSqn0LKl4/Cbw1zxi6zdS5t+zR0VLJScDMBssjizvIQM1BTgJmtjc811CHcBIws7w4EXSAgZLADeef2KJIzKwbORG0uSxJwOMDzGwo3EfQxg52c5CZtYDvCNpYowHDTgJm1ixOBG2qUZOQk4CZNZMTQRtyEjCzVnIiaDONksAxk8a1MBIzKwt3FreJIy+9jS1bt9c9Pmn8vtw056QWRmRmZZH5jkDSmDwDKbOBkkDP2FHcMff0FkZkZmUyYCKQdKKkh4B16fbRkr6Ze2QlsWrj5gHvBFbOO6OFEZlZ2WRpGvrfJAvILAGIiJ9LOiXXqEpi1cbNvPtbd9U9fsW73sA5070im5nlK1MfQUQ8kSwrvEv9r7CWWaMk4BHDZtYqWRLBE5JOBCJdYOaTpM1EtvcaPR3kJGBmrZSls/g84AKSxej7SNYW/niOMXW94y+/ve4xJwEza7UsdwSHRcQHKndI+mPgznxC6n6btmytuX9azxgnATNruSx3BH+XcZ9l0KhJ6PaLTm1dIGZmqbp3BJLeDJwI9Ej6VMWh/UnWILZB8tQRZtaOGjUNjQLGpmX2q9j/X8B78gyqGx3zhWV1j3lhGTMrUt1EEBE/Bn4s6dqI2NjCmLrSb1/qr7l//OgR7hcws0Jl6Sx+UdKVwOuBfXfujIi35BZVl2nUJLT6829rYSRmZnvK0ll8PfALYCrwBeAxYGWOMXWV+UvrD7lwv4CZtYMsieBVEfEdYFtE/DgiPgq8Kee4usaCFRtq7u8ZO6rFkZiZ1ZalaWhb+vspSW8HngQm5RdS92jUJOSJ5MysXWRJBJdLGgdcRDJ+YH/gwjyD6garNm6ue8xNQmbWTgZMBBFxc/ryOeA02DWy2BqoN6HcKdMmtDgSM7PGGg0oGw68j2SOodsiYq2kdwCfA0YDb2xNiJ3n0EuW1tw/DLju3OmtDcbMbACN7gi+AxwI3AtcJWkj8GZgbkTc1ILYOtbW7VFz/wY3CZlZG2qUCHqBoyJih6R9gWeB10bE060JrTPV6yAekXlRUDOz1mp0edoaETsAIuJ3wCODTQKSZkh6WNJ6SXPrlDlV0mpJD0r68WDO324On3dr3WPrr/DdgJm1p0Z3BK+TtCZ9LeCQdFtARMRRjU6c9jF8AziDZB2DlZKWRMRDFWXGA98EZkTE45JevfdVKd5L/Ttq7vdcQmbWzholgsOHeO4TgPURsQFA0mLgTOChijLnADdGxOMAEfHMED+zMFPrNAmNGi7PJWRmba3RpHNDnWhuIvBExXYfUP3IzKHASEnLSWY4/XpEXFd9IkmzgdkAkye352LutbuH4ZEvzWppHGZmg5VnF6Zq7Ku+Xo4AjgPeDrwN+J+SDt3jTRELI6I3Inp7enqaH+kQ1esg9pgBM+sEWUYW760+ksdPd5pEMj1FdZlnI+IF4AVJK4CjgUdyjKtlPGbAzDpBpjsCSaMlHTbIc68EpkmaKmkUcDawpKrMPwMnSxoh6RUkTUf1p+tsQx/6zj0193saCTPrFAMmAkl/BqwGbku3j5FUfUHfQ0T0A3OAZSQX93+KiAclnSfpvLTMuvS8a0gGrl0TEWv3si6FWPHLZ4sOwcxsSLI0Df01yRNAywEiYrWkKVlOHhFLgaVV+xZUbV8JXJnlfO2m3loD40fn2eJmZtZcWZqG+iPiudwj6UD11hrwqmNm1kmyfHVdK+kcYLikacAngdpTa5qZWcfJckfwCZL1il8G/pFkOuoLc4ypIxzzhWU197uT2Mw6TZY7gsMi4hLgkryD6SS/fam/6BDMzJoiyx3B1yT9QtIXJb0+94g6wIWL76+5f9L4fVsciZnZ0A2YCCLiNOBUYBOwUNIDkublHVg7u2l19bi4xB1zT29xJGZmQ5dpQFlEPB0RVwHnkYwpuDTPoNrZGV9dXnP/qOG1ZtQwM2t/WQaUHS7pryWtBa4meWJoUu6Rtalfbnqh5n5PLmdmnSpLZ/F3ge8Db42I2m0iJefFx8yskw2YCCLiTa0IpBMc8tnas4x6LWIz62R1E4Gkf4qI90l6gN2nj860Qlk3qrMmvZlZR2t0R/BX6e93tCKQTnXeKQcXHYKZ2ZDUbd6OiKfSlx+PiI2VP8DHWxNe+6i3+MzcWUNd0dPMrFhZ+jnPqLFvZrMDMTOzYjTqIzif5Jv/wZLWVBzaD7gz78A6wQ3nn1h0CGZmQ9aoj+AfgVuBvwHmVux/PiJ+k2tUbebgOs1Cxx30yhZHYmbWfI0SQUTEY5IuqD4g6Q/KlAx2FB2AmVmOBrojeAewiuTx0co5FAIo9eMyp0ybUHQIZmZNUTcRRMQ70t9TWxdO+6k3t9B1505vbSBmZjnJMtfQH0sak77+c0lfkzQ5/9DaQ725hczMukWWx0e/Bbwo6WjgfwAbgb/PNao2UW/swLSeMS2OxMwsP1kXrw/gTODrEfF1kkdIS+v2i04tOgQzs6bJMvvo85I+C3wQOFnScGBkvmEVr97dgMcOmFm3yXJHcBbJwvUfjYingYnAlblG1cY8dsDMuk2WpSqfBq4Hxkl6B/C7iLgu98jakNckNrNulOWpofcB9wLvBd4H3CPpPXkHVqRVGzfX3O81ic2sG2XpI7gEOD4ingGQ1AP8G/DDPAMr0nsX3FV0CGZmLZOlj2DYziSQ+nXG93WsHTUWoBnR1TU2szLLckdwm6RlJOsWQ9J5vDS/kNrT+iu8HKWZdacsaxZ/RtJ/B04imW9oYUT8KPfICjK1zmOjZmbdqtF6BNOArwCHAA8An46IX7UqsKLUWpZ4pJuFzKyLNbrELQJuBt5NMgPp3w325JJmSHpY0npJcxuUO17S9nZ9GmnxxzyIzMy6V6Omof0i4tvp64cl/WwwJ05HIH+DZKnLPmClpCUR8VCNcl8Glg3m/Hk4fN6tNfd7EJmZdbNGiWBfSW/k9+sQjK7cjoiBEsMJwPqI2AAgaTHJfEUPVZX7BHADcPwgY2+6l/q9BI2ZlU+jRPAU8LWK7acrtgN4ywDnngg8UbHdB+w2ib+kicC70nPVTQSSZgOzASZPbu0M2F6Axsy6XaOFaU4b4rlVY191X+zfAhdHxHapVvFdsSwEFgL09vbW6s/NjRegMbNul2Ucwd7qAw6s2J4EPFlVphdYnCaBCcAsSf0RcVOOcdVUbyUyM7Nul2ciWAlMkzQV+BVwNnBOZYHKZTAlXQvcXEQSAK9EZmbllVsiiIh+SXNIngYaDiyKiAclnZceX5DXZzdLz9hRRYdgZpa7AROBknabDwAHR8Rl6XrFfxgR9w703ohYStV0FPUSQER8OFPEOTjy0ttq7l8574wWR2Jm1npZxsx+E3gz8P50+3mS8QFdY8vW7UWHYGZWmCxNQ9Mj4lhJ9wNExGZJXd9m4sdGzawsstwRbEtH/wbsWo+g60de+bFRMyuLLIngKuBHwKslfQm4A7gi16jMzKxlskxDfb2kVcDpJIPE3hkR63KPrEUuXHx/0SGYmRUqy1NDk4EXgX+p3BcRj+cZWKvctLp6jJuZWblk6Sy+haR/QMC+wFTgYeD1OcZVqNFel9LMSiRL09AbKrclHQt8LLeI2sC6y2cWHYKZWcsM+qtvOv104VNGm5lZc2TpI/hUxeYw4FhgU24RtVC9EcVmZmWSpY9gv4rX/SR9BjfkE05reUSxmdkAiSAdSDY2Ij7TongK5xHFZlY2dfsIJI2IiO0kTUGl4RHFZlY2je4I7iVJAqslLQF+AOyatD8ibsw5NjMza4EsfQR/APyaZF3hneMJAujoRPDOq+8oOgQzs7bQKBG8On1iaC2/TwA7tXTd4Dys7ntuj331V002M+tejRLBcGAs2Rah7wofO+XgokMwM2u5RongqYi4rGWRtIG5sw4vOgQzs5ZrNLLYLSVmZiXQKBGc3rIoWmz+0q6ZRdvMbMjqJoKI+E0rA2mlBSs2FB2CmVnb8HzLKY8oNrOyciJIeUSxmZWVE4GZWck5EZiZlVzpEsEZX11edAhmZm2ldIngl5te2GOfB0yYWZmVLhHU8sPzTyw6BDOzwjgRAMcd9MqiQzAzK4wTgZlZyeWaCCTNkPSwpPWS5tY4/gFJa9KfuyQdnWc8Zma2p9wSQbre8TeAmcARwPslHVFV7FHgTyLiKOCLwMK84jEzs9ryvCM4AVgfERsiYiuwGDizskBE3BURm9PNu4FJOcZjZmY15JkIJgJPVGz3pfvqORe4tdYBSbMl3Sfpvk2bNjUxRDMzyzMRZF7ZTNJpJIng4lrHI2JhRPRGRG9PT08TQzQzsyyL1++tPuDAiu1JwJPVhSQdBVwDzIyIX+cYj5mZ1ZDnHcFKYJqkqZJGAWcDSyoLSJoM3Ah8MCIeyTEWwAvSmJnVktsdQUT0S5oDLAOGA4si4kFJ56XHFwCXAq8CvikJoD8ievOK6dt3PJrXqc3MOlaeTUNExFJgadW+BRWv/wL4izxjqLR9x55dFNN6xrTq483M2lLpRxbfftGpRYdgZlao0icCM7OycyIwMys5JwIzs5JzIjAzKzknAjOzkitNIrhw8f1Fh2Bm1pZKkwhuXvPUHvv222d4AZGYmbWX0iSC/hqDya796PQCIjEzay+lSQS1eK1iM7OSJwIzM3MiMDMrPScCM7OScyIwMys5JwIzs5IrTSKormhpKm5mNoDSXA/3GTGs4baZWVmV5mr4cv+OhttmZmVVmkRQfdl3GjAzS5QmEZiZWW2lSQTD1XjbzKysSpMI9hm5+0yjrxjlmUfNzKBEiWBr//bdtl/a5l4CMzMoUSIYNbzq8dGRpam6mVlDpbkaTthvn922D9h/34IiMTNrL6VJBD1jR+22feTEcQVFYmbWXkqRCFZt3Myqx5/bbd/yRzYVFI2ZWXspRSK4e8Ov99i35XfbCojEzKz9lCIR3FMjEZx4yIQCIjEzaz+lSAQrH9u827aA6871wvVmZlCSRDBmn90Hj72qquPYzKzMck0EkmZIeljSeklzaxyXpKvS42skHZtHHJ8647CG22ZmZZZbIpA0HPgGMBM4Ani/pCOqis0EpqU/s4Fv5RWPmZnVlucdwQnA+ojYEBFbgcXAmVVlzgSui8TdwHhJBzQ7kEV3Ptpw28yszPJMBBOBJyq2+9J9gy2DpNmS7pN036ZNe/H8f0TjbTOzEsszEdSa6Ln6CpylDBGxMCJ6I6K3p6dn0IF89KSDG26bmZXZiBzP3QccWLE9CXhyL8oM2TnTJwNw69qnmHnkAbu2zcws30SwEpgmaSrwK+Bs4JyqMkuAOZIWA9OB5yLiqTyCOWf6ZCcAM7MacksEEdEvaQ6wDBgOLIqIByWdlx5fACwFZgHrgReBj+QVj5mZ1ZbnHQERsZTkYl+5b0HF6wAuyDMGMzNrrBQji83MrD4nAjOzknMiMDMrOScCM7OSU3TYKFtJm4CNe/n2CcCzTQynE7jO5eA6l8NQ6nxQRNQckdtxiWAoJN0XEb1Fx9FKrnM5uM7lkFed3TRkZlZyTgRmZiVXtkSwsOgACuA6l4PrXA651LlUfQRmZranst0RmJlZFScCM7OS68pEIGmGpIclrZc0t8ZxSboqPb5G0rFFxNlMGer8gbSuayTdJenoIuJspoHqXFHueEnbJb2nlfHlIUudJZ0qabWkByX9uNUxNluGf9vjJP2LpJ+nde7oWYwlLZL0jKS1dY43//oVEV31QzLl9X8CBwOjgJ8DR1SVmQXcSrJC2puAe4qOuwV1PhF4Zfp6ZhnqXFHu/5HMgvueouNuwd95PPAQMDndfnXRcbegzp8Dvpy+7gF+A4wqOvYh1PkU4FhgbZ3jTb9+deMdwQnA+ojYEBFbgcXAmVVlzgSui8TdwHhJB7Q60CYasM4RcVdEbE437yZZDa6TZfk7A3wCuAF4ppXB5SRLnc8BboyIxwEiotPrnaXOAewnScBYkkTQ39owmyciVpDUoZ6mX7+6MRFMBJ6o2O5L9w22TCcZbH3OJflG0ckGrLOkicC7gAV0hyx/50OBV0paLmmVpA+1LLp8ZKnz1cDhJMvcPgD8VUTsaE14hWj69SvXhWkKohr7qp+RzVKmk2Suj6TTSBLBSblGlL8sdf5b4OKI2J58Wex4Weo8AjgOOB0YDfxU0t0R8UjeweUkS53fBqwG3gIcAtwu6ScR8V85x1aUpl+/ujER9AEHVmxPIvmmMNgynSRTfSQdBVwDzIyIX7cotrxkqXMvsDhNAhOAWZL6I+KmlkTYfFn/bT8bES8AL0haARwNdGoiyFLnjwDzI2lAXy/pUeB1wL2tCbHlmn796samoZXANElTJY0CzgaWVJVZAnwo7X1/E/BcRDzV6kCbaMA6S5oM3Ah8sIO/HVYasM4RMTUipkTEFOCHwMc7OAlAtn/b/wycLGmEpFcA04F1LY6zmbLU+XGSOyAkvQY4DNjQ0ihbq+nXr667I4iIfklzgGUkTxwsiogHJZ2XHl9A8gTJLGA98CLJN4qOlbHOlwKvAr6ZfkPujw6euTFjnbtKljpHxDpJtwFrgB3ANRFR8zHETpDx7/xF4FpJD5A0m1wcER07PbWk7wOnAhMk9QGfB0ZCftcvTzFhZlZy3dg0ZGZmg+BEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBtKZ0tdHXFz5QGZbc04fOulfRo+lk/k/TmvTjHNZKOSF9/rurYXUONMT3Pzv8ua9MZN8cPUP4YSbOa8dnWvfz4qLUlSVsiYmyzyzY4x7XAzRHxQ0lvBb4SEUcN4XxDjmmg80r6HvBIRHypQfkPA70RMafZsVj38B2BdQRJYyX9e/pt/QFJe8w0KukASSsqvjGfnO5/q6Sfpu/9gaSBLtArgNem7/1Ueq61ki5M942RdEs6//1aSWel+5dL6pU0HxidxnF9emxL+vv/Vn5DT+9E3i1puKQrJa1UMsf8xzL8Z/kp6WRjkk5Qss7E/envw9KRuJcBZ6WxnJXGvij9nPtr/Xe0Eip67m3/+KfWD7CdZCKx1cCPSEbB758em0AyqnLnHe2W9PdFwCXp6+HAfmnZFcCYdP/FwKU1Pu9a0vUKgPcC95BM3vYAMIZkeuMHgTcC7wa+XfHecenv5STfvnfFVFFmZ4zvAr6Xvh5FMovkaGA2MC/dvw9wHzC1RpxbKur3A2BGur0/MCJ9/afADenrDwNXV7z/CuDP09fjSeYgGlP039s/xf503RQT1jVeiohjdm5IGglcIekUkqkTJgKvAZ6ueM9KYFFa9qaIWC3pT4AjgDvTqTVGkXyTruVKSfOATSQztJ4O/CiSCdyQdCNwMnAb8BVJXyZpTvrJIOp1K3CVpH2AGcCKiHgpbY46Sr9fRW0cMA14tOr9oyWtBqYAq4DbK8p/T9I0kpkoR9b5/LcC/03Sp9PtfYHJdPZ8RDZETgTWKT5AsvrUcRGxTdJjJBexXSJiRZoo3g78vaQrgc3A7RHx/gyf8ZmI+OHODUl/WqtQRDwi6TiS+V7+RtK/RsRlWSoREb+TtJxk6uSzgO/v/DjgExGxbIBTvBQRx0gaB9wMXABcRTLfzn9ExLvSjvXldd4v4N0R8XCWeK0c3EdgnWIc8EyaBE4DDqouIOmgtMy3ge+QLPd3N/DHkna2+b9C0qEZP3MF8M70PWNImnV+IumPgBcj4h+Ar6SfU21bemdSy2KSicJOJplMjfT3+TvfI+nQ9DNriojngE8Cn07fMw74VXr4wxVFnydpIttpGfAJpbdHkt5Y7zOsPJwIrFNcD/RKuo/k7uAXNcqcCqyWdD9JO/7XI2ITyYXx+5LWkCSG12X5wIj4GUnfwb0kfQbXRMT9wBuAe9MmmkuAy2u8fSGwZmdncZV/JVmX9t8iWX4RknUiHgJ+pmTR8v/DAHfsaSw/J5ma+X+R3J3cSdJ/sNN/AEfs7CwmuXMYmca2Nt22kvPjo2ZmJec7AjOzknMiMDMrOScCM7OScyIwMys5JwIzs5JzIjAzKzknAjOzkvv/hhqw+2NaqfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# area under curve (AUC) of receiver operating charisteristic (ROC) curve\n",
    "\n",
    "# predict probabilities\n",
    "model_probs = logistic_regression.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "model_probs = model_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "model_auc = roc_auc_score(y_test, model_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('Logistic regression: ROC AUD = %.3f' % (model_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "# fpr, tpr: false positive rate, true positive rate\n",
    "fpr, tpr, _ = roc_curve(y_test, model_probs)\n",
    "\n",
    "# plot roc curve\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best params:\n",
      "{'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__C': [0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, scoring='precision', verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Logistic Regression with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing stay the same\n",
    "# only edit the whole model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampler\n",
    "adasyn = ADASYN(random_state=20210517,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# as 'pipeline' in sklearn library does not support 'adasyn'\n",
    "# 'adasyn' function has no .fit_transform\n",
    "# have to use 'make_pipeline' in imblearn library\n",
    "\n",
    "logistic_adasyn = make_pipeline(preprocessor, adasyn ,LogisticRegression(random_state=20210510, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  ['age', 'education',\n",
       "                                                   'hours_per_week']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['workclass',\n",
       "                                                   'marital_status',\n",
       "                                                   'occupation', 'relationship',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'capital_change',\n",
       "                                                   'native_country'])])),\n",
       "                ('adasyn', ADASYN(n_jobs=-1, random_state=20210517)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(n_jobs=-1, random_state=20210510))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 37.130s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logistic_adasyn.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time2 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.771\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83     12397\n",
      "           1       0.51      0.87      0.64      3835\n",
      "\n",
      "    accuracy                           0.77     16232\n",
      "   macro avg       0.73      0.81      0.74     16232\n",
      "weighted avg       0.85      0.77      0.79     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.74      0.83     24635\n",
      "           1       0.52      0.88      0.65      7827\n",
      "\n",
      "    accuracy                           0.77     32462\n",
      "   macro avg       0.74      0.81      0.74     32462\n",
      "weighted avg       0.85      0.77      0.79     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(logistic_adasyn)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(logistic_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-d5f1b4b34ab3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogistic_adasyn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best params:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "\n",
    "param_grid = {\n",
    "    'logisticregression__penalty': ['l1', 'l2'],\n",
    "    'logisticregression__C': [0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(logistic_adasyn, param_grid, scoring='precision', verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Linear Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing stay the same\n",
    "# only edit the whole model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model pipeline\n",
    "\n",
    "linear_svc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',LinearSVC(random_state=20210518))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 5.805s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "linear_svc.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time3 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.844\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     12397\n",
      "           1       0.71      0.57      0.63      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     24635\n",
      "           1       0.72      0.57      0.64      7827\n",
      "\n",
      "    accuracy                           0.84     32462\n",
      "   macro avg       0.80      0.75      0.77     32462\n",
      "weighted avg       0.84      0.84      0.84     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(linear_svc)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(linear_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best params:\n",
      "{'classifier__C': 10, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__loss': ['hinge','squared_hinge'],\n",
    "    'classifier__C': [0.1, 1.0, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(linear_svc, param_grid, scoring='precision', verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 4.914s\n",
      "model score: 0.844\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     12397\n",
      "           1       0.71      0.58      0.64      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     24635\n",
      "           1       0.71      0.58      0.64      7827\n",
      "\n",
      "    accuracy                           0.84     32462\n",
      "   macro avg       0.79      0.75      0.77     32462\n",
      "weighted avg       0.84      0.84      0.84     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole model pipeline with best params\n",
    "\n",
    "linear_svc = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',LinearSVC(C=10, random_state=20210518))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "linear_svc.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time3 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time3)\n",
    "\n",
    "# model evaluation\n",
    "print_score(linear_svc)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 K Nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing stay the same\n",
    "# only edit the whole model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model pipeline\n",
    "\n",
    "kneighbors = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 0.115s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "kneighbors.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time4 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.825\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89     12397\n",
      "           1       0.64      0.58      0.61      3835\n",
      "\n",
      "    accuracy                           0.82     16232\n",
      "   macro avg       0.76      0.74      0.75     16232\n",
      "weighted avg       0.82      0.82      0.82     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     24635\n",
      "           1       0.77      0.69      0.73      7827\n",
      "\n",
      "    accuracy                           0.88     32462\n",
      "   macro avg       0.84      0.81      0.82     32462\n",
      "weighted avg       0.87      0.88      0.87     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(kneighbors)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(kneighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best params:\n",
      "{'classifier__n_neighbors': 50}\n"
     ]
    }
   ],
   "source": [
    "# grid search 1\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [5, 10, 25, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(kneighbors, param_grid, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best params:\n",
      "{'classifier__n_neighbors': 40}\n"
     ]
    }
   ],
   "source": [
    "# grid search 2\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [30, 40, 50, 60, 70, 80, 90]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(kneighbors, param_grid, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 0.159s\n",
      "model score: 0.843\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     12397\n",
      "           1       0.71      0.57      0.63      3835\n",
      "\n",
      "    accuracy                           0.84     16232\n",
      "   macro avg       0.79      0.75      0.77     16232\n",
      "weighted avg       0.84      0.84      0.84     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90     24635\n",
      "           1       0.73      0.60      0.66      7827\n",
      "\n",
      "    accuracy                           0.85     32462\n",
      "   macro avg       0.81      0.77      0.78     32462\n",
      "weighted avg       0.84      0.85      0.85     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole model pipeline with best params\n",
    "\n",
    "kneighbors = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',KNeighborsClassifier(n_neighbors=40))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "kneighbors.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time4 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time4)\n",
    "\n",
    "# model evaluation\n",
    "print_score(kneighbors)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(kneighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.6 Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing stay the same\n",
    "# only edit the whole model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole model pipeline\n",
    "\n",
    "decision_tree = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=20210521, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 1.795s\n"
     ]
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time5 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.783\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85     12397\n",
      "           1       0.54      0.60      0.57      3835\n",
      "\n",
      "    accuracy                           0.78     16232\n",
      "   macro avg       0.70      0.72      0.71     16232\n",
      "weighted avg       0.79      0.78      0.79     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24635\n",
      "           1       0.86      0.99      0.92      7827\n",
      "\n",
      "    accuracy                           0.96     32462\n",
      "   macro avg       0.93      0.97      0.95     32462\n",
      "weighted avg       0.96      0.96      0.96     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print_score(decision_tree)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 225 candidates, totalling 1125 fits\n",
      "Best params:\n",
      "{'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# grid search 1\n",
    "\n",
    "depth = [\n",
    "    1, 2, 3, 4, 5,\n",
    "    6, 7, 8, 9, 10,\n",
    "    12, 14, 16, 18, 20\n",
    "]\n",
    "\n",
    "num_leaf = [\n",
    "    1, 2, 3, 4, 5,\n",
    "    6, 7, 8, 9, 10,\n",
    "    12, 14, 16, 18, 20\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "        'classifier__max_depth': depth,\n",
    "        'classifier__min_samples_leaf': num_leaf\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params:\n",
      "{'classifier__max_depth': 60}\n"
     ]
    }
   ],
   "source": [
    "# grid search 2\n",
    "\n",
    "depth = [\n",
    "    20, 30, 40, 50, 60,\n",
    "    70, 80, 90, 100, 200\n",
    "]\n",
    "\n",
    "param_grid = {\n",
    "        'classifier__max_depth': depth\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, scoring='precision', verbose=1, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training time: 1.851s\n",
      "model score: 0.783\n",
      "\n",
      "\n",
      "Classification report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85     12397\n",
      "           1       0.54      0.60      0.57      3835\n",
      "\n",
      "    accuracy                           0.78     16232\n",
      "   macro avg       0.70      0.72      0.71     16232\n",
      "weighted avg       0.79      0.78      0.79     16232\n",
      "\n",
      "Classification report on train data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     24635\n",
      "           1       0.86      0.99      0.92      7827\n",
      "\n",
      "    accuracy                           0.96     32462\n",
      "   macro avg       0.93      0.97      0.95     32462\n",
      "weighted avg       0.96      0.96      0.96     32462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole model pipeline with best params\n",
    "\n",
    "decision_tree = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier',DecisionTreeClassifier(max_depth=60, random_state=20210521, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# model fitting\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time5 = end_time - start_time\n",
    "print(f'model training time: %.3fs' % time5)\n",
    "\n",
    "# model evaluation\n",
    "print_score(decision_tree)\n",
    "\n",
    "# classification reports\n",
    "print_classfication_reports(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search try scoring focus on precision\n",
    "# check regression parameters\n",
    "## drop col with low coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
